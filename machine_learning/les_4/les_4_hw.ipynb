{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIu2DPx5tWcg"
   },
   "source": [
    "## Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENiWYl_EtWcm"
   },
   "source": [
    "### 1. Загрузите тренировочные и тестовые датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_uf-KNwQtWcn",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/w_lander/anaconda3/envs/dowgrade/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sqevAjp-tWcr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "train = pd.read_csv('data/TrainData.csv')\n",
    "test = pd.read_csv('data/TestData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 15), (2500, 15))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQkpwQGHtWcr"
   },
   "source": [
    "### 2. Оцените баланс классов в задаче\n",
    "- Затем попытайтесь устно ответить на вопрос, можно ли использовать accuracy как метрику качества в задаче?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "csjvNCCutWcs",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    5708\n",
       "1    1792\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# для дисбаланса классов, метрика accuracy не подходит. Необходимо использовать precision или recall в зависимости от задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xB_ReQ62tWct"
   },
   "source": [
    "### 3. Постройте baseline-модель:\n",
    "- разбейте TrainData на тренировочные (Train) и тестовые данные (Test);\n",
    "- обучите LogisticRegression и SVC с параметрами по умолчанию на тренировочных данных (Train);\n",
    "- примените модели на тестовых данных (Test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7500 entries, 0 to 7499\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   f1      7500 non-null   int64  \n",
      " 1   f2      7425 non-null   float64\n",
      " 2   f3      7500 non-null   int64  \n",
      " 3   f4      7500 non-null   float64\n",
      " 4   f5      7500 non-null   int64  \n",
      " 5   f6      7500 non-null   float64\n",
      " 6   f7      5625 non-null   float64\n",
      " 7   f8      7500 non-null   float64\n",
      " 8   f9      7500 non-null   float64\n",
      " 9   f10     7500 non-null   float64\n",
      " 10  f11     7490 non-null   float64\n",
      " 11  f12     7500 non-null   int64  \n",
      " 12  f13     7500 non-null   int64  \n",
      " 13  f14     7500 non-null   float64\n",
      " 14  target  7500 non-null   int64  \n",
      "dtypes: float64(9), int64(6)\n",
      "memory usage: 879.0 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WUfRVj5ctWcu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "X = train.drop(['target', 'f2', 'f7', 'f11'], axis=1)\n",
    "Y = train['target']\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, train_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2250, 11), (2250,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      4000\n",
      "           1       0.63      0.49      0.55      1250\n",
      "\n",
      "    accuracy                           0.81      5250\n",
      "   macro avg       0.74      0.70      0.72      5250\n",
      "weighted avg       0.80      0.81      0.80      5250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_log_r = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "pred_test = model_log_r.predict(X_test)\n",
    "\n",
    "print('TEST LogisticRegression')\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST model_svc\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4000\n",
      "           1       0.69      0.42      0.52      1250\n",
      "\n",
      "    accuracy                           0.82      5250\n",
      "   macro avg       0.76      0.68      0.70      5250\n",
      "weighted avg       0.80      0.82      0.80      5250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_svc = SVC().fit(X_train, y_train)\n",
    "\n",
    "pred_train = model_svc.predict(X_train)\n",
    "\n",
    "pred_test = model_svc.predict(X_test)\n",
    "\n",
    "print('TEST model_svc')\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Обе модели справились примерно одинаково, и не очень хорошо определяюи 1 класс, без балансировки классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYQnr8CftWcv"
   },
   "source": [
    "### 4. Улучшите модели\n",
    "Попробуйте улучшить качество обученных моделей:\n",
    "- можете задавать class_weights;\n",
    "- можете изменять параметры модели;\n",
    "- можете вручную или при помощи методов Python генерировать новые признаки и/или удалять существующие.\n",
    "\n",
    "Это самая важная и творческая часть задания. Проводите как можно больше экспериментов!\n",
    "\n",
    "Проведите минимиум три эксперимента: для каждого типа модели минимум один эксперимент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZJrKNIw8tWcw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST balanced LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.83      4000\n",
      "           1       0.51      0.84      0.64      1250\n",
      "\n",
      "    accuracy                           0.77      5250\n",
      "   macro avg       0.72      0.79      0.74      5250\n",
      "weighted avg       0.84      0.77      0.79      5250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_log_r = LogisticRegression(class_weight='balanced').fit(X_train, y_train)\n",
    "\n",
    "pred_test = model_log_r.predict(X_test)\n",
    "\n",
    "print('TEST balanced LogisticRegression')\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST balanced model_svc\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.74      0.83      4000\n",
      "           1       0.51      0.86      0.64      1250\n",
      "\n",
      "    accuracy                           0.77      5250\n",
      "   macro avg       0.73      0.80      0.73      5250\n",
      "weighted avg       0.84      0.77      0.78      5250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_svc = SVC(class_weight='balanced').fit(X_train, y_train)\n",
    "\n",
    "pred_test = model_svc.predict(X_test)\n",
    "\n",
    "print('TEST balanced model_svc')\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfu3yy_7tWcy"
   },
   "source": [
    "### 5. Оцените на отложенной выборке качество наилучшей модели\n",
    "В пунктах 3 и 4 вы построили много разных моделей.\n",
    "\n",
    "Возьмите ту, которая дала наилучшее качество на тестовых данных (Test). Примените её на отложенной выборке (TestData) и выведите на экран значение метрики f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def_test = test.drop(['target', 'f2', 'f7', 'f11'], axis=1)\n",
    "def_y = test['target']\n",
    "def_test_scaled = StandardScaler().fit_transform(def_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "upHUOfrktWcy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST balanced model_svc\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.66      0.76      1913\n",
      "           1       0.39      0.72      0.51       587\n",
      "\n",
      "    accuracy                           0.67      2500\n",
      "   macro avg       0.64      0.69      0.63      2500\n",
      "weighted avg       0.77      0.67      0.70      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = model_svc.predict(def_test_scaled)\n",
    "\n",
    "print('TEST balanced model_svc')\n",
    "print(classification_report(def_y, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZT0rMuStWcz"
   },
   "source": [
    "### 6. Выполните хитрый трюк\n",
    "Часто смешивание различных моделей даёт улучшение итогового предсказания. Попробуйте смешать две лучшие модели по формуле:\n",
    "$$pred_{final} = \\alpha\\cdot pred_1 + (1-\\alpha)\\cdot pred_2$$.\n",
    "\n",
    "Значение $\\alpha$ подберите в цикле по Test-выборке. Оцените качество на отложенной выборке.\n",
    "\n",
    "Удалось ли добиться улучшения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3DdSsk6gtWc7"
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b9imFkLtWc8"
   },
   "source": [
    "### 7. Сделайте выводы\n",
    "\n",
    "Запишите в отдельной ячейке текстом выводы о проделанной работе. Для этого ответьте на вопросы:\n",
    "- Какие подходы вы использовали для улучшения работы baseline-моделей?\n",
    "- Какого максимального качества удалось добиться на Test-данных?\n",
    "- Какое при этом получилось качество на отложенной выборке?\n",
    "- Ваша модель переобучилась, недообучилась или обучилась как надо?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wWgT4ulytWc-"
   },
   "outputs": [],
   "source": [
    "# Модель немлохо определяет 0 класс и  1 класс, балансировка улучшила результаты, но на достаточно большой выборке модель училась на одинаковых наблюдениях.\n",
    "# Можно попробовать более сложные модели, а также создать новые признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnFjm55atWc-"
   },
   "source": [
    "Важный комментарий! В реальных задачах не следует ожидать, что машинным обучением всегда удастся решить задачу с хорошим качеством. Но использовать все имеющиеся у вас в арсенале методы для достижения наилучшего результата нужно."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
