{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d22ea63a-560b-42ad-abb0-48de57409f24",
   "metadata": {},
   "source": [
    "### Урок 3. Инструменты работы и визуализации ч.2\n",
    "\n",
    "Условие: есть набор данных о продажах продуктов с информацией о дате продаж, категории продукта, количестве и выручке от продаж.\n",
    "\n",
    "Используя Apache Spark, загрузите предоставленный набор данных в DataFrame (пример данных ниже)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "06d4e594-b795-4e11-9430-df0718e2e4cd",
   "metadata": {},
   "source": [
    "С использованием оконных функций, рассчитайте среднее выручки от продаж для каждой категории продукта.\n",
    "Примените операцию pivot для того, чтобы преобразовать полученные данные таким образом, чтобы в качестве строк были категории продуктов, в качестве столбцов были дни, а значениями были средние значения выручки от продаж за соответствующий день."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4a7ce5-9d2c-47d6-a7e8-1c53ae238721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, \"2023-11-20\", \"Electronics\", 100, 12000),\n",
    "    (2, \"2023-11-21\", \"Electronics\", 110, 13000),\n",
    "    (3, \"2023-11-22\", \"Electronics\", 105, 12500),\n",
    "    (4, \"2023-11-20\", \"Clothing\", 300, 15000),\n",
    "    (5, \"2023-11-21\", \"Clothing\", 280, 14000),\n",
    "    (6, \"2023-11-22\", \"Clothing\", 320, 16000),\n",
    "    (7, \"2023-11-20\", \"Books\", 150, 9000),\n",
    "    (8, \"2023-11-21\", \"Books\", 200, 12000),\n",
    "    (9, \"2023-11-22\", \"Books\", 180, 10000)\n",
    "]\n",
    "columns = [\"id\", \"date\", \"category\", \"quantity\", \"revenue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dbc1ac9-a57f-43c9-be1a-addd1cd3708d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import (avg, col, rank, row_number, sum, round, dense_rank)\n",
    "from pyspark.sql.types import DateType, IntegerType, StringType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"WindowFunctionExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8920a3c8-f557-4db3-8915-2fe9ac412977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Создание DataFrame\n",
    "df = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd034943-45e7-4361-b97e-3a42b27d273b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------+-------+\n",
      "| id|      date|   category|quantity|revenue|\n",
      "+---+----------+-----------+--------+-------+\n",
      "|  1|2023-11-20|Electronics|     100|  12000|\n",
      "|  2|2023-11-21|Electronics|     110|  13000|\n",
      "|  3|2023-11-22|Electronics|     105|  12500|\n",
      "|  4|2023-11-20|   Clothing|     300|  15000|\n",
      "|  5|2023-11-21|   Clothing|     280|  14000|\n",
      "|  6|2023-11-22|   Clothing|     320|  16000|\n",
      "|  7|2023-11-20|      Books|     150|   9000|\n",
      "|  8|2023-11-21|      Books|     200|  12000|\n",
      "|  9|2023-11-22|      Books|     180|  10000|\n",
      "+---+----------+-----------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c90c9a3-e8be-4420-8ee2-e2af41abed84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Преобразование типа дынных в столбце 'date'\n",
    "df = df.withColumn(\"date\", col(\"date\").cast(DateType()))\n",
    "#df = df.withColumn(\"category\", col(\"category\").cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2914612f-3419-4330-8696-b141b312ea39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------+-------+----------+\n",
      "| id|      date|   category|quantity|revenue|row_number|\n",
      "+---+----------+-----------+--------+-------+----------+\n",
      "|  7|2023-11-20|      Books|     150|   9000|         1|\n",
      "|  8|2023-11-21|      Books|     200|  12000|         2|\n",
      "|  9|2023-11-22|      Books|     180|  10000|         3|\n",
      "|  4|2023-11-20|   Clothing|     300|  15000|         1|\n",
      "|  5|2023-11-21|   Clothing|     280|  14000|         2|\n",
      "|  6|2023-11-22|   Clothing|     320|  16000|         3|\n",
      "|  1|2023-11-20|Electronics|     100|  12000|         1|\n",
      "|  2|2023-11-21|Electronics|     110|  13000|         2|\n",
      "|  3|2023-11-22|Electronics|     105|  12500|         3|\n",
      "+---+----------+-----------+--------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mean каждой категории продукта\n",
    "w = df.withColumn('row_number',  row_number() \\\n",
    "                  .over(Window.partitionBy('category') \\\n",
    "                  .orderBy('date')))\n",
    "\n",
    "w.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02128a2a-6f37-4a08-b7c2-383ca31db63c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|   category|avg_revenue|\n",
      "+-----------+-----------+\n",
      "|Electronics|    12500.0|\n",
      "|   Clothing|    15000.0|\n",
      "|      Books|   10333.33|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w.groupBy('category').agg(round(avg(\"revenue\"), 2).alias(\"avg_revenue\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42e6dfb9-dc70-4c40-ae3e-df3b2b27f257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Примените операцию pivot для того, чтобы преобразовать полученные данные таким образом, чтобы в качестве строк были категории продуктов, \n",
    "# в качестве столбцов были дни, а значениями были средние значения выручки от продаж за соответствующий день.\n",
    "pivot_df = w.groupBy('category').pivot(\"date\").agg(avg(\"revenue\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13c5ed0f-dfc1-42a8-aa1f-6b5aacf8c154",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+----------+\n",
      "|   category|2023-11-20|2023-11-21|2023-11-22|\n",
      "+-----------+----------+----------+----------+\n",
      "|Electronics|   12000.0|   13000.0|   12500.0|\n",
      "|   Clothing|   15000.0|   14000.0|   16000.0|\n",
      "|      Books|    9000.0|   12000.0|   10000.0|\n",
      "+-----------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivot_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
