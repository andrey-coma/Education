{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed78146-2378-42f1-b16c-cdb7f0eee328",
   "metadata": {},
   "source": [
    "# Проверка работы модели на новых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c20c3b-cae0-4bae-8099-ba0f7a2c0125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Импорт неоходимых библиотек\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Векторизация текстовых данных TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Нормализация по длине документа\n",
    "from sklearn.preprocessing import normalize\n",
    "# Преобразование в разреженную матрицу\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Метрики\n",
    "from sklearn.metrics import (accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve)\n",
    "\n",
    "# Понижение размерности\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Лингивистические модули\n",
    "from razdel import tokenize # сегментация русскоязычного текста на токены и предложения\n",
    "import pymorphy2  # Морфологический анализатор\n",
    "import nltk # лингивистический модуль nltk \n",
    "from nltk.corpus import stopwords # импортируем стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc12b49-0fe5-4fcc-bd81-6ef5d7f30fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/w_lander/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Подготовка функций\n",
    "\n",
    "# Функция разметки коментариев с использованим поля stars (от 1-3 негивный отзыв, от 4-5 позитивный отзыв)\n",
    "def get_label_target(num_stars: int) -> int:\n",
    "    if num_stars in (1, 2, 3):\n",
    "        return 0  # отзыв негативный\n",
    "    else:\n",
    "        return 1  # отзыв позитивный\n",
    "\n",
    "\n",
    "# Функция очистки отзывов от лишних пробелов, символов и тд. и тп\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    на выходе очищеный текст\n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "    text = re.sub('n', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# Функция токенизации, лемматизация, удаления стоп-слов\n",
    "cache = {}\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatization(text: str) -> str:\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    \n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w) > 1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopwords_ru] # [6]\n",
    "    \n",
    "    return words_lem_without_stopwords\n",
    "\n",
    "# Создадим список стоп-слов из модуля NLTK\n",
    "nltk.download('stopwords')\n",
    "stopwords_ru = stopwords.words('russian')\n",
    "\n",
    "# Уберем частицу не из словаря стоп-слов\n",
    "stopwords_ru.remove('не')\n",
    "\n",
    "# Дополним стоп-слова из внешнего локального словаря\n",
    "with open('stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "    \n",
    "stopwords_ru += additional_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59056145-a5c5-4525-b292-29c2753af567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка тестового датафрейма\n",
    "#df = pd.read_csv('../pars/data_train/vkus_vils_products.csv')\n",
    "df = pd.read_csv('../pars/data_test/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a810326-ef26-47f1-8326-f6ad7faec46e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_982482/1355504995.py:23: FutureWarning: Possible nested set at position 39\n",
      "  text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.9 s, sys: 672 ms, total: 14.6 s\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Предварительная обработка\n",
    "df['target'] = df['stars'].apply(get_label_target) # Создаем колонку с целевой переменной \"target_by_stars\"\n",
    "df['comment_pre_processing'] = df['comment'].apply(lambda x: clean_text(x)) # очищенными от лишних данных \n",
    "df['comment_pre_processing'] = df['comment_pre_processing'].apply(lambda x: lemmatization(x)) # применим функцию lemmatization\n",
    "df['comment_pre_processing'] = df['comment_pre_processing'].apply(lambda x: ' '.join(x)) # приведем знаячения к строкам\n",
    "df.dropna(subset=['comment_pre_processing'], inplace=True) # удалим пропуски в процессе лемматизации (при их наличии)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), sublinear_tf=True, max_features=None) # Применение TF-IDF к признаку 'comment_pre_processing'\n",
    "df_tfidf_matrix = tfidf_vectorizer.fit_transform(df['comment_pre_processing'])\n",
    "# Нормализация матрицы TF-IDF по длине документа\n",
    "\n",
    "df_tfidf_matrix_normalized = normalize(df_tfidf_matrix, norm='l2', axis=1)\n",
    "# Преобразование в разреженную матрицу\n",
    "sparse_matrix = csr_matrix(df_tfidf_matrix_normalized)\n",
    "# Понижение размерности TSNE\n",
    "tsne = TSNE(n_components=2, random_state=42, n_jobs=-1, perplexity=20)\n",
    "tsne_result = tsne.fit_transform(df_tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe887e6-ec19-4090-969e-65448d012ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# загружаем модель\n",
    "from joblib import dump, load\n",
    "clf = load('models/best_model.pkl') "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c85ef21-ea3b-4ca8-9619-7bc06fa46c63",
   "metadata": {
    "tags": []
   },
   "source": [
    "from joblib import dump, load\n",
    "clf = load('models/catboost_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6109af9-80b3-4ec3-9405-b00c3a0cc36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(tsne_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "775d7d91-a3e4-4a82-852b-5ee9953a1dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    409\n",
       "0    281\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fddbe895-e139-4dbe-bd88-847d63f13075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7127819548872181"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df['target'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f18cf41-5c0f-4f56-b23c-587d22aef085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.93      0.73       281\n",
      "           1       0.93      0.58      0.71       409\n",
      "\n",
      "    accuracy                           0.72       690\n",
      "   macro avg       0.76      0.76      0.72       690\n",
      "weighted avg       0.79      0.72      0.72       690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['target'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "678ec32d-74ca-4c61-a2e1-f3eb727c04eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(['comment_pre_processing', 'target'], axis=1, inplace=True) # перед записью в БД удаляем 'comment_pre_processing'\n",
    "df['status'] = pred # добавляем колонку с предсказаниями 'status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba28ddbc-2573-4229-897b-888ca2c4405c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>stars</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>weight</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Сергей</td>\n",
       "      <td>Отличная зелень</td>\n",
       "      <td>18 мая 2025  · Карта: xxx51</td>\n",
       "      <td>https://vkusvill.ru/goods/salat-rukola-125-g-2...</td>\n",
       "      <td>Салат Рукола, 125 г</td>\n",
       "      <td>Овощи</td>\n",
       "      <td>5</td>\n",
       "      <td>205</td>\n",
       "      <td>руб</td>\n",
       "      <td>/шт</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Ирина</td>\n",
       "      <td>Хлеб от Пеко присутствует привкус ванили а это...</td>\n",
       "      <td>14 мая 2025  · Карта: xxx40</td>\n",
       "      <td>https://vkusvill.ru/goods/baton-nareznoy-polov...</td>\n",
       "      <td>Батон нарезной, половинка</td>\n",
       "      <td>Особое</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>руб</td>\n",
       "      <td>/шт</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ГАЛИЯ</td>\n",
       "      <td>Постоянно горелый</td>\n",
       "      <td>21 мая 2025  · Карта: xxx33</td>\n",
       "      <td>https://vkusvill.ru/goods/baton-nareznoy-polov...</td>\n",
       "      <td>Батон нарезной, половинка</td>\n",
       "      <td>Особое</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>руб</td>\n",
       "      <td>/шт</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author                                            comment  \\\n",
       "66   Сергей                                    Отличная зелень   \n",
       "498   Ирина  Хлеб от Пеко присутствует привкус ванили а это...   \n",
       "421   ГАЛИЯ                                  Постоянно горелый   \n",
       "\n",
       "                            date  \\\n",
       "66   18 мая 2025  · Карта: xxx51   \n",
       "498  14 мая 2025  · Карта: xxx40   \n",
       "421  21 мая 2025  · Карта: xxx33   \n",
       "\n",
       "                                                   url  \\\n",
       "66   https://vkusvill.ru/goods/salat-rukola-125-g-2...   \n",
       "498  https://vkusvill.ru/goods/baton-nareznoy-polov...   \n",
       "421  https://vkusvill.ru/goods/baton-nareznoy-polov...   \n",
       "\n",
       "                       product category  stars  price currency weight  status  \n",
       "66         Салат Рукола, 125 г    Овощи      5    205      руб    /шт       0  \n",
       "498  Батон нарезной, половинка   Особое      4     41      руб    /шт       1  \n",
       "421  Батон нарезной, половинка   Особое      1     41      руб    /шт       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cb74e83-dbb9-4b4f-bbfe-718a6aa7d0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('result.csv', encoding='utf8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
